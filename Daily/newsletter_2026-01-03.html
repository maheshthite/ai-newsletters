<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Newsletter - January 03, 2026</title>
    <style>
        body { font-family: 'Segoe UI', Arial, sans-serif; max-width: 800px; margin: 40px auto; padding: 20px; background-color: #f5f5f5; }
        .header { background: linear-gradient(135deg, #0066cc 0%, #0052a3 100%); color: white; padding: 30px; border-radius: 10px; margin-bottom: 30px; }
        h1 { margin: 0; font-size: 2.5em; }
        .subtitle { opacity: 0.9; margin-top: 10px; }
        .section { background: white; margin: 20px 0; padding: 25px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .section h2 { color: #0066cc; border-bottom: 3px solid #0066cc; padding-bottom: 10px; margin-top: 0; }
        .alert-high { background: #ffe0e0; border-left: 4px solid #f44336; padding: 15px; margin: 15px 0; }
        .alert-medium { background: #fff9e6; border-left: 4px solid #ff9800; padding: 15px; margin: 15px 0; }
        .item { margin: 20px 0; padding: 15px; border-left: 4px solid #0066cc; background: #f9f9f9; }
        .item-title { font-size: 1.2em; font-weight: bold; margin-bottom: 8px; }
        .item-title a { color: #0066cc; text-decoration: none; }
        .item-title a:hover { text-decoration: underline; }
        .item-meta { color: #666; font-size: 0.9em; margin-bottom: 10px; }
        .item-summary { line-height: 1.6; color: #333; }
        .badge { display: inline-block; padding: 4px 10px; border-radius: 4px; font-size: 0.85em; margin-right: 8px; }
        .badge-high { background: #d4edda; color: #155724; }
        .badge-medium { background: #fff3cd; color: #856404; }
        .badge-score { background: #e3f2fd; color: #0d47a1; }
        .tags { margin-top: 10px; }
        .tag { display: inline-block; background: #e0e0e0; padding: 3px 8px; border-radius: 3px; font-size: 0.8em; margin-right: 5px; margin-top: 5px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>AI Newsletter - Daily</h1>
        <div class="subtitle">January 03, 2026</div>
    </div>
    <div class="section">
        <h2>ðŸ”® AI Prediction Markets</h2>
        <pre style="white-space: pre-wrap; font-family: inherit;">- **[Tesla Optimus on sale before 2027?](https://kalshi.com/markets/teslaoptimus)**
  - Kalshi - 24% probability â€¢ $110,746 total volume

- **[Will OpenAI announce the creation of AGI?](https://kalshi.com/markets/oaiagi)**
  - Kalshi - 21% probability â€¢ $93,161 total volume

- **[Will a court find that OpenAI has infringed the copyright of the New York Times?](https://kalshi.com/markets/nytoai)**
  - Kalshi - 54% probability â€¢ $39,135 total volume

- **[What will be the top AI model this month?](https://kalshi.com/markets/kxtopmodel)**
  - Kalshi - 0% probability â€¢ $32,257 total volume

- **[Will OpenAI have a top-ranked AI model before 2027?](https://kalshi.com/markets/kxtopai)**
  - Kalshi - 46% probability â€¢ $1,853 total volume

- **[AI regulation by 2027?](https://kalshi.com/markets/kxailegislation)**
  - Kalshi - 26% probability â€¢ $672 total volume

- **[Will an AI model reach a 3 hour time horizon with 80% reliability during 2026?](https://www.metaculus.com/questions/41140/)**
  - Metaculus â€¢ 326 forecasters

- **[Will Nvidia&#39;s stock price close below $100 on any day in 2026?](https://www.metaculus.com/questions/40972/)**
  - Metaculus â€¢ 312 forecasters

- **[Will the U.S. enact an AI safety federal statute or executive order in 2026?](https://www.metaculus.com/questions/41193/)**
  - Metaculus â€¢ 305 forecasters

- **[Will OpenAI file for an IPO during 2026?](https://www.metaculus.com/questions/41141/)**
  - Metaculus â€¢ 293 forecasters

</pre>
    </div>
    <div class="section">
        <h2>ðŸ”¥ Top Stories</h2>
        <div class="item">
            <div class="item-title"><a href="https://openai.com/index/openai-grove" target="_blank">Announcing OpenAI Grove Cohort 2</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 70</span>
                <span class="badge badge-medium">ProductLaunch</span>
                Source: OpenAI Blog | Jan 02, 2026
            </div>
            <div class="item-summary">Applications are now open for OpenAI Grove Cohort 2, a 5-week founder program designed for individuals at any stage, from pre-idea to product. Participants receive $50K in API credits, early access to AI tools, and hands-on mentorship from the OpenAI team.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://arxiv.org/abs/2511.12884" target="_blank">Trending Papers</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 58</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Papers with Code | Jan 03, 2026
            </div>
            <div class="item-summary">Featured on Papers with Code - ArXiv: 2511.12884</div>
            <div class="tags">
                <span class="tag">research</span>
                <span class="tag">arxiv</span>
                <span class="tag">paperswithcode</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/02/india-orders-musks-x-to-fix-grok-over-obscene-ai-content/" target="_blank">India orders Muskâ€™s X to fix Grok over â€˜obsceneâ€™ AI content</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 02, 2026
            </div>
            <div class="item-summary">India's IT ministry has given X 72 hours to submit an action-taken report.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/podcast/how-ai-is-reshaping-work-and-who-gets-to-do-it-according-to-mercors-ceo/" target="_blank">How AI is reshaping work and who gets to do it, according to Mercorâ€™s CEO</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 02, 2026
            </div>
            <div class="item-summary">Three-year-old startup Mercor has become a $10 billion middleman in AIâ€™s data gold rush. The company connects AI labs like OpenAI and Anthropic with former employees of Goldman Sachs, McKinsey, and white-shoe law firms, paying them up to $200 an hour to share their industry expertise and train the AI models that could eventually automate their former employers out of business. Today weâ€™re bringing [â€¦].</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/02/nvidias-ai-empire-a-look-at-its-top-startup-investments/" target="_blank">Nvidiaâ€™s AI empire: A look at its top startup investments</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 02, 2026
            </div>
            <div class="item-summary">Over the last two years, Nvidia has used its ballooning fortunes to invest in over 100 AI startups. Here are the giant semiconductor's largest investments.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

    </div>
    <div class="section">
        <h2>ðŸ“„ Research Papers</h2>
        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1q25g6v/recommended_venue_for_applied_ml_paper_r/" target="_blank">Recommended Venue for Applied ML Paper [R]</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/MachineLearning | Jan 02, 2026
 | By /u/Fantastic-Nerve-4056
            </div>
            <div class="item-summary">Hi there, I have been recently working on a project involving human-like thinking in chess. While there are existing works such as Maia (NeurIPS 2024), I have been working on a model that naturally develops this kind of thinking. The core algorithm is just an extension of the existing models, with some novelty in how it is used (but the human-like thinking comes naturally), and the results are implicitly comparable or better than the baselines.</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1q2j5mf/presentable_publishable_paper_r/" target="_blank">Presentable / Publishable Paper? [R]</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/MachineLearning | Jan 03, 2026
 | By /u/ReddRobben
            </div>
            <div class="item-summary">I created an Agentic Physics Engine (APE), created some experiments, and ran them against a few different LLM's. I'm looking for feedback on whether the paper is interesting, and if so, where could I possible publish or present it? The Dimensionality Barrier in LLM Physics Reasoning Redd Howard Robben January 2025 Abstract We evaluate three frontier LLMs (GPT-4o-mini, Gemini-2.0-Flash, Qwen-72B) on 1D and 2D collision prediction using APE, a multi-agent system where LLM-powered agents negotiate physics outcomes validated by symbolic physics.</div>
            <div class="tags">
                <span class="tag">GPT</span>
                <span class="tag">LLM</span>
                <span class="tag">AI</span>
                <span class="tag">RAG</span>
                <span class="tag">Gemini</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1q1xbw3/r_survey_paper_agentic_llms/" target="_blank">[R] Survey paper Agentic LLMs</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/MachineLearning | Jan 02, 2026
 | By /u/pppeer
            </div>
            <div class="item-summary">Where might agentic AI go? To have some idea, it is good to understand the present state of the art, and our recently published survey paper on Agentic LLMs (JAIR) will give you perspectives on how agentic LLMs: i) reason, ii) act, iii) interact, and how these capabilities reinforce each other in a virtuous cycle. The paper comes with hundreds of references, so enough seeds and ideas to explore further.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">AI</span>
                <span class="tag">artificial intelligence</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=KUekLTqV1ME" target="_blank">Researchers Built a Tiny Economy. AIs Broke It Immediately</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 48</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: YouTube - Two Minute Papers | Dec 14, 2025
 | By Two Minute Papers
            </div>
            <div class="item-summary">SimWorld, a simulated video game city, was used to study AI agent behavior in a delivery economy. Key findings revealed that "greed" often led to higher profits but also greater variance, while conscientious AI agents performed more reliably. Surprisingly, agents with high "openness" tended to go broke by overspending, and market saturation led to laziness rather than increased effort.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=Nao16-6l6dQ" target="_blank">[Paper Analysis] The Free Transformer (and some Variational Autoencoder stuff)</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 48</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: YouTube - Yannic Kilcher | Nov 01, 2025
 | By Yannic Kilcher
            </div>
            <div class="item-summary">This video introduces a transformer model that incorporates latent variables to make underlying decisions about generated sequences, unlike standard transformers that rely solely on random token sampling. This approach aims to improve consistency by allowing a latent choice, such as a positive or negative movie review sentiment, to inform the entire generation process. The model is designed for scenarios where underlying latent factors significantly influence the data.</div>
            <div class="tags">
                <span class="tag">transformer</span>
            </div>
        </div>

    </div>
    <div class="section">
        <h2>ðŸ“º Videos</h2>
        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=KUekLTqV1ME" target="_blank">Researchers Built a Tiny Economy. AIs Broke It Immediately</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 48</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: YouTube - Two Minute Papers | Dec 14, 2025
 | By Two Minute Papers
            </div>
            <div class="item-summary">SimWorld, a simulated video game city, was used to study AI agent behavior in a delivery economy. Key findings revealed that "greed" often led to higher profits but also greater variance, while conscientious AI agents performed more reliably. Surprisingly, agents with high "openness" tended to go broke by overspending, and market saturation led to laziness rather than increased effort.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=Nao16-6l6dQ" target="_blank">[Paper Analysis] The Free Transformer (and some Variational Autoencoder stuff)</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 48</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: YouTube - Yannic Kilcher | Nov 01, 2025
 | By Yannic Kilcher
            </div>
            <div class="item-summary">This video introduces a transformer model that incorporates latent variables to make underlying decisions about generated sequences, unlike standard transformers that rely solely on random token sampling. This approach aims to improve consistency by allowing a latent choice, such as a positive or negative movie review sentiment, to inform the entire generation process. The model is designed for scenarios where underlying latent factors significantly influence the data.</div>
            <div class="tags">
                <span class="tag">transformer</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=EWvNQjAaOHw" target="_blank">How I use LLMs</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Feb 27, 2025
 | By Andrej Karpathy
            </div>
            <div class="item-summary">Large language models like ChatGPT interact by processing text as tokens, building a "context window" or working memory of the conversation. These models are trained on vast amounts of internet data, essentially learning to predict the next token in a sequence, which allows them to generate human-like text and gain knowledge about the world. The ecosystem of such AI tools is growing, with many alternatives to ChatGPT now available from various tech companies and startups.</div>
            <div class="tags">
                <span class="tag">LLM</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=7xTGNNLPyMI" target="_blank">Deep Dive into LLMs like ChatGPT</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Feb 05, 2025
 | By Andrej Karpathy
            </div>
            <div class="item-summary">Large language models like ChatGPT are built through a multi-stage process, starting with pre-training on a massive, filtered dataset of internet text. This data undergoes extensive cleaning, including URL filtering, text extraction, language identification, and deduplication, to create a high-quality corpus. The model then learns patterns and relationships within this text data to generate human-like responses.</div>
            <div class="tags">
                <span class="tag">GPT</span>
                <span class="tag">LLM</span>
                <span class="tag">ChatGPT</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU" target="_blank">Let's reproduce GPT-2 (124M)</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Jun 09, 2024
 | By Andrej Karpathy
            </div>
            <div class="item-summary">This video guides viewers through reproducing the 124 million parameter GPT-2 model. It highlights that while OpenAI released the model and its weights, the original TensorFlow code can be challenging to work with. The tutorial leverages Hugging Face Transformers for a PyTorch-based implementation, allowing for efficient reproduction and analysis of the model's learned embeddings.</div>
            <div class="tags">
                <span class="tag">GPT</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=zduSFxRajkE" target="_blank">Let's build the GPT Tokenizer</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Feb 20, 2024
 | By Andrej Karpathy
            </div>
            <div class="item-summary">Tokenization is the crucial process of converting text into numerical tokens for large language models, and it significantly impacts their performance. State-of-the-art models use complex algorithms like Byte Pair Encoding, which breaks text into chunks rather than individual characters. Understanding tokenization is vital as many LLM quirks, like difficulties with arithmetic or non-English languages, often stem from how text is tokenized.</div>
            <div class="tags">
                <span class="tag">GPT</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=zjkBMFhNj_g" target="_blank">[1hr Talk] Intro to Large Language Models</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Nov 23, 2023
 | By Andrej Karpathy
            </div>
            <div class="item-summary">Large language models like Llama 270b are essentially two files: a large parameters file and a code file to run it. Training these models involves a massive computational effort, akin to a lossy compression of the internet, costing millions of dollars. Fundamentally, these models work by predicting the next word in a sequence, a task that surprisingly forces them to learn a vast amount of world knowledge.</div>
            <div class="tags">
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=_uo7CXd33Uc" target="_blank">NVIDIAâ€™s AI Finally Solved Walking In Games</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Two Minute Papers | Dec 21, 2025
 | By Two Minute Papers
            </div>
            <div class="item-summary">This research introduces a new AI system that creates physically simulated characters, eliminating common animation bugs like sliding feet. These agents learn to move naturally across various terrains and interact organically with their environment. The technology, combining a "brain" for pathfinding and a "muscle" for movement, has potential applications beyond gaming, including training safer autonomous vehicles with realistic pedestrian behavior.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=FMMpUO1uAYk" target="_blank">What the Freakiness of 2025 in AI Tells Us About 2026</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 23, 2025
 | By AI Explained
            </div>
            <div class="item-summary">In 2025, AI saw significant advancements in reasoning models and the creation of dynamic, persistent virtual worlds with models like Gemini 3 Pro and Genie3. However, this year also highlighted the rise of AI-generated "slop" that can deceive viewers and raised concerns about the impact on creativity and trust. Despite these challenges, public sentiment towards AI remained cautiously positive, though debates continued regarding its ethical implications and the true meaning of artificial creativity.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=WHqaF4jbUYU" target="_blank">Gemini Exponential, Demis Hassabis' â€˜Proto-AGIâ€™ coming, but â€¦</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 19, 2025
 | By AI Explained
            </div>
            <div class="item-summary">Google's new Gemini 3 Flash model shows significant improvements in reasoning and knowledge compared to previous versions, even outperforming heavier models on certain benchmarks. However, a key weakness is its tendency to confidently provide incorrect answers rather than stating it doesn't know. This highlights a broader industry trend where models are incentivized to produce answers, potentially at the expense of accuracy and honesty.</div>
            <div class="tags">
                <span class="tag">AGI</span>
                <span class="tag">Gemini</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=4p73Uu_jZ10" target="_blank">GPT 5.2: OpenAI Strikes Back</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 12, 2025
 | By AI Explained
            </div>
            <div class="item-summary">OpenAI's GPT 5.2 demonstrates impressive performance across various benchmarks, claiming to exceed human expert levels in certain knowledge work tasks. However, its results are heavily influenced by increased "thinking time" or token allocation, making direct comparisons with other models like Gemini 3 Pro complex. The selection and interpretation of benchmarks also present challenges in definitively assessing model capabilities.</div>
            <div class="tags">
                <span class="tag">GPT</span>
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=iO844izo9kw" target="_blank">You Are Being Told Contradictory Things About AI</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 05, 2025
 | By AI Explained
            </div>
            <div class="item-summary">The video highlights conflicting narratives surrounding AI, particularly regarding job displacement and the path to artificial general intelligence. While some predict rapid white-collar job automation, data suggests current AI can only automate a portion of tasks, with actual job losses depending on company strategies and worker adaptation. Experts disagree on whether simply scaling current AI models will lead to AGI, with some believing it's achievable through continued scaling and minor modifications, while others suggest current approaches may plateau and that new, unknown ingredients are necessary.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=9hv4nr_46Ao" target="_blank">Nano Banana Pro: But Did You Catch These 10 Details?</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Nov 20, 2025
 | By AI Explained
            </div>
            <div class="item-summary">Google's Nano Banana Pro is a significant advancement in text-to-image generation, impressing with its quality and professional application. Key features include its ability to integrate live search for grounded results and sophisticated double-exposure capabilities. However, users should remain cautious of potential inaccuracies, particularly in infographics, and be aware of the model's limitations with font generation and certain prompts.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=4yYcN_mFi18" target="_blank">PhD Bodybuilder Predicts The Future of AI (97% Certain) [Dr. Mike Israetel]</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Machine Learning Street Talk | Dec 24, 2025
 | By Machine Learning Street Talk
            </div>
            <div class="item-summary">The discussion posits that true intelligence requires more than just simulated capabilities, drawing parallels to the imperfect nature of virtual worlds like The Matrix. It explores the distinction between Artificial General Intelligence (AGI) and Artificial Super Intelligence (ASI), with ASI predicted to emerge around 2026-2027 and AGI shortly after. The key takeaway is that ASI will be defined by its radical superiority across many human cognitive domains, evidenced by both its underlying abilities and its tangible impact on the world.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

    </div>
    <div class="section">
        <h2>ðŸ“° News</h2>
        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/02/in-2026-ai-will-move-from-hype-to-pragmatism/" target="_blank">In 2026, AI will move from hype to pragmatism</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 02, 2026
            </div>
            <div class="item-summary">In 2026, here's what you can expect from the AI industry: new architectures, smaller models, world models, reliable agents, physical AI, and products designed for real-world use.</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">RAG</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://analyticsindiamag.com/ai-trends/from-openai-to-groq-6-vc-trends-that-captured-ai-funding-gold-rush-of-2025/" target="_blank">From OpenAI to Groq, 6 VC Trends That Captured AI Funding Gold Rush of 2025</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Analytics India Magazine | Jan 03, 2026
            </div>
            <div class="item-summary">Global investment in AI reached $202.3 billion by Q3 2025, a 75% year-on-year increase. The post From OpenAI to Groq, 6 VC Trends That Captured AI Funding Gold Rush of 2025 appeared first on Analytics India Magazine.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1q1wyfi/d_open_sourced_loop_attention_for_qwen306b/" target="_blank">[D] Open sourced Loop Attention for Qwen3-0.6B: two-pass global + local attention with a learnable gate (code + weights + training script)</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/MachineLearning | Jan 02, 2026
 | By /u/Wittica
            </div>
            <div class="item-summary">Recently I was curious about Loop Attention and what effect it would have on small language models. I finished a small architectural tweak specifically for Qwen's architecture and recently tried the full training for Qwen3-0.6B and wanted to share it openly. Instead of doing attention once, Loop Attention does a quick global attention pass, then a second pass that looks at a local sliding window, and a learnable gate blends the two.</div>
            <div class="tags">
                <span class="tag">transformer</span>
                <span class="tag">AI</span>
                <span class="tag">attention</span>
                <span class="tag">model</span>
                <span class="tag">training</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1q2mej3/p_seeking_feedback_on_a_gpu_profiler_i_made_as_a/" target="_blank">[P] seeking feedback on a gpu profiler I made as a Python package</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/MachineLearning | Jan 03, 2026
 | By /u/stella-skinny
            </div>
            <div class="item-summary">Recently released a project that profiles GPU. It classifies operations as compute/memory/overhead bound and suggests fixes. works on any gpu through auto-calibration Let me know https://pypi.org/project/gpu-regime-profiler/ pip install gpu-regime-profiler submitted by /u/stella-skinny [link] [comments].</div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1q1u32q/how_can_i_prune_vlms_or_llms_d/" target="_blank">How Can I prune VLMs or LLMs? [D]</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/MachineLearning | Jan 02, 2026
 | By /u/MinimumArtichoke5679
            </div>
            <div class="item-summary">I know basics of pruning for deep learning models. However, I don't know how to do it for larger models. Sharing your knowledge and resources will guide me, thanks submitted by /u/MinimumArtichoke5679 [link] [comments].</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">deep learning</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1q1xo9b/d_wacv_2026_broadening_participation_scholarship/" target="_blank">[D] WACV 2026 Broadening Participation scholarship results</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/MachineLearning | Jan 02, 2026
 | By /u/Forsaken-Order-7376
            </div>
            <div class="item-summary">Did anyone hear back anything? submitted by /u/Forsaken-Order-7376 [link] [comments].</div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/artificial/comments/1q2gu7a/i_figured_out_how_to_completely_bypass_nano/" target="_blank">I figured out how to completely bypass Nano Banana Pro's invisible watermark with diffusion-based post processing.</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/artificial | Jan 03, 2026
 | By /u/LiteratureAcademic34
            </div>
            <div class="item-summary">Iâ€™ve been doing AI safety research on the robustness of digital watermarking for AI images, focusing on Google DeepMindâ€™s SynthID (as used in Nano Banana Pro). In my testing, I found that diffusion-based post-processing can disrupt SynthID in a way that makes common detection checks fail, while largely preserving the imageâ€™s visible content. Iâ€™ve documented before/after examples and detection screenshots showing the watermark being detected pre-processing and not detected after.</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">diffusion</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/artificial/comments/1q2hxs8/asi_could_literally_create_solar_systems_is/" target="_blank">"ASI could literally create solar systems." - is everyone losing their minds? Or am I stupid?</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/artificial | Jan 03, 2026
 | By /u/sheriffderek
            </div>
            <div class="item-summary">https://www.reddit.com/r/accelerate/comments/1q2crc2/comment/nxcs7tn/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button Some of the claims Iâ€™m seeing feel like saying "humans are about to start flying like Superman." Superman is fun! I'm glad we have imaginations. But are people operating inside symbolic systems that no longer answer to the physical world?</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">AGI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/artificial/comments/1q1yrn3/data_centers_generate_50x_more_tax_revenue_per/" target="_blank">Data centers generate 50x more tax revenue per gallon of water than golf courses in Arizona</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/artificial | Jan 02, 2026
 | By /u/Beachbunny_07
            </div>
            <div class="item-summary">The stat: Golf courses in AZ use ~30x more water than all data centers combined. The payoff: Data centers generate roughly 50x more tax revenue per gallon of water used. The proposal: Swap out golf courses for data centers to keep water usage flat while making billions for the state. submitted by /u/Beachbunny_07 [link] [comments].</div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/artificial/comments/1q2lyh8/what_is_the_flying_cars_promise_of_ai_and_whats/" target="_blank">What is the "flying cars" promise of AI and what's the subsequent "just drone quad copters" reality that will befall it?</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 51</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: Reddit - r/artificial | Jan 03, 2026
 | By /u/PopularRightNow
            </div>
            <div class="item-summary">Every new technology has unrealistic expectations and a subsequent reality that falls way short of the initial promise. With 3d printing, people really thought 3d printing machines would print machines that would print machines that would print machines that would print anything that we can imagine under the sun. It was to be the new manufacturing paradigm.</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">AGI</span>
                <span class="tag">generative</span>
            </div>
        </div>

    </div>
</body>
</html>
