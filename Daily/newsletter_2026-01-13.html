<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Newsletter - January 13, 2026</title>
    <style>
        body { font-family: 'Segoe UI', Arial, sans-serif; max-width: 800px; margin: 40px auto; padding: 20px; background-color: #f5f5f5; }
        .header { background: linear-gradient(135deg, #0066cc 0%, #0052a3 100%); color: white; padding: 30px; border-radius: 10px; margin-bottom: 30px; }
        h1 { margin: 0; font-size: 2.5em; }
        .subtitle { opacity: 0.9; margin-top: 10px; }
        .section { background: white; margin: 20px 0; padding: 25px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .section h2 { color: #0066cc; border-bottom: 3px solid #0066cc; padding-bottom: 10px; margin-top: 0; }
        .alert-high { background: #ffe0e0; border-left: 4px solid #f44336; padding: 15px; margin: 15px 0; }
        .alert-medium { background: #fff9e6; border-left: 4px solid #ff9800; padding: 15px; margin: 15px 0; }
        .item { margin: 20px 0; padding: 15px; border-left: 4px solid #0066cc; background: #f9f9f9; }
        .item-title { font-size: 1.2em; font-weight: bold; margin-bottom: 8px; }
        .item-title a { color: #0066cc; text-decoration: none; }
        .item-title a:hover { text-decoration: underline; }
        .item-meta { color: #666; font-size: 0.9em; margin-bottom: 10px; }
        .item-summary { line-height: 1.6; color: #333; }
        .badge { display: inline-block; padding: 4px 10px; border-radius: 4px; font-size: 0.85em; margin-right: 8px; }
        .badge-high { background: #d4edda; color: #155724; }
        .badge-medium { background: #fff3cd; color: #856404; }
        .badge-score { background: #e3f2fd; color: #0d47a1; }
        .tags { margin-top: 10px; }
        .tag { display: inline-block; background: #e0e0e0; padding: 3px 8px; border-radius: 3px; font-size: 0.8em; margin-right: 5px; margin-top: 5px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>AI Newsletter - Daily</h1>
        <div class="subtitle">January 13, 2026</div>
    </div>
    <div class="section">
        <h2>üîÆ AI Prediction Markets</h2>
        <pre style="white-space: pre-wrap; font-family: inherit;">- **[Will any NVIDIA GPUs better than the H200 be allowed to be exported to China before March 14, 2026?](https://www.metaculus.com/questions/41343/)**
  - Metaculus ‚Ä¢ 338 forecasters

- **[Will OpenAI API token prices fall before March 14, 2026?](https://www.metaculus.com/questions/41336/)**
  - Metaculus ‚Ä¢ 296 forecasters

</pre>
    </div>
    <div class="section">
        <h2>üî• Top Stories</h2>
        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/meta-backed-hupo-finds-growth-after-pivot-to-ai-sales-coaching-from-mental-wellness/" target="_blank">Meta-backed Hupo finds growth after pivot to AI sales coaching from mental wellness</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 13, 2026
            </div>
            <div class="item-summary">Hupo, backed by Meta, pivoted from mental wellness to AI sales coaching for banks and insurers, and secured a $10M Series A led by DST Global.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/hands-on-with-bee-amazons-latest-ai-wearable/" target="_blank">Hands-on with Bee, Amazon‚Äôs latest AI wearable</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 13, 2026
            </div>
            <div class="item-summary">We tried Amazon's new AI wearable Bee. It's not for pro users yet, but more features are expected this year.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/why-amazon-bought-bee-an-ai-wearable/" target="_blank">Why Amazon bought Bee, an AI wearable</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">Amazon explains where its wearable Bee fits in and whether it will merge with Alexa.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/mark-zuckerberg-says-meta-is-launching-its-own-ai-infrastructure-initiative/" target="_blank">Mark Zuckerberg says Meta is launching its own AI infrastructure initiative</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">Meta is ramping up its efforts to build out its AI capacity ‚Äî Zuckerberg said the company intended to drastically expand its energy footprint in the coming years.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/anthropic-announces-claude-for-healthcare-following-openais-chatgpt-health-reveal/" target="_blank">Anthropic announces Claude for Healthcare following OpenAI‚Äôs ChatGPT Health reveal</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">Anthropic's Claude for Healthcare is unveiled about a week after OpenAI announced its ChatGPT Health product.</div>
            <div class="tags">
                <span class="tag">GPT</span>
                <span class="tag">AI</span>
                <span class="tag">ChatGPT</span>
                <span class="tag">Claude</span>
            </div>
        </div>

    </div>
    <div class="section">
        <h2>üìÑ Research Papers</h2>
        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1qb2spz/r_guiding_llm_agents_via_gametheoretic_feedback/" target="_blank">[R] Guiding LLM agents via game-theoretic feedback loops</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/MachineLearning | Jan 12, 2026
 | By /u/Obvious-Language4462
            </div>
            <div class="item-summary">Abstract-style summary We introduce a closed-loop method for guiding LLM-based agents using explicit game-theoretic feedback. Agent interaction logs are transformed into structured graphs, a zero-sum attacker‚Äìdefender game is solved on the graph (Nash equilibrium), and the resulting equilibrium statistics are injected back into the agent‚Äôs system prompt as a strategic control signal. Method ‚Ä¢ Automatic graph extraction from agent logs ‚Ä¢ Effort-based scoring replacing static probabilities ‚Ä¢ Nash equilibrium computation on dynamically inferred graphs ‚Ä¢ Periodic feedback into the agent‚Äôs planning loop Results ‚Ä¢ Success rate: 20.0% ‚Üí 42.9% (44-run benchmark) ‚Ä¢ Tool-use variance: ‚àí5.2√ó ‚Ä¢ Expected time-to-success: ‚àí2.7√ó Paper (PDF): https://arxiv.org/pdf/2601.05887 Code: https://github.com/aliasrobotics/cai submitted by /u/Obvious-Language4462 [link] [comments].</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Game Theory</span>
                <span class="tag">Nash Equilibrium</span>
                <span class="tag">Model Training</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/MachineLearning/comments/1qastrk/r_paper_on_evaluative_fingerprints_stable_and/" target="_blank">[R] paper on Evaluative Fingerprints: Stable and Systematic Differences in LLM Evaluator Behavior</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/MachineLearning | Jan 12, 2026
 | By /u/PromptOutlaw
            </div>
            <div class="item-summary">TL;DR A lot of LLM eval pipelines treat ‚ÄúLLM-as-judge‚Äù as a rough but usable proxy for quality. I kept running into something that felt off: different judges would give very different scores, yet each judge was weirdly consistent with itself. This paper tries to measure that effect and show it‚Äôs not random noise.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Model Training</span>
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/artificial/comments/1qb46h5/the_intelligence_paradox_why_centralized_ai_is/" target="_blank">The Intelligence Paradox: Why centralized AI is hitting a "Power Wall" and the case for decentralized inference hubs</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/artificial | Jan 12, 2026
 | By /u/Foreign-Job-8717
            </div>
            <div class="item-summary">As we scale to GPT-5.2 and beyond, the energy footprint of centralized data centers in the US is becoming a physical limit. I'm theorizing that the next step isn't "bigger models," but smarter routing to specialized, regionally-hosted inference hubs. If we can't shrink the models, we must optimize the path to the user.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">AI</span>
                <span class="tag">Generative AI</span>
                <span class="tag">Model Training</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/LocalLLaMA/comments/1qbjbrf/baichuanincbaichuanm3235b_hugging_face/" target="_blank">baichuan-inc/Baichuan-M3-235B ¬∑ Hugging Face</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/LocalLLaMA | Jan 13, 2026
 | By /u/jacek2023
            </div>
            <div class="item-summary">üåü Model Overview Baichuan-M3 is Baichuan AI's new-generation medical-enhanced large language model, a major milestone following Baichuan-M2. In contrast to prior approaches that primarily focus on static question answering or superficial role-playing, Baichuan-M3 is trained to explicitly model the clinical decision-making process, aiming to improve usability and reliability in real-world medical practice. Rather than merely producing "plausible-sounding answers" or high-frequency vague recommendations like "you should see a doctor soon," the model is trained to proactively acquire critical clinical information, construct coherent medical reasoning pathways, and systematically constrain hallucination-prone behaviors.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Generative AI</span>
                <span class="tag">Model Training</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/LocalLLaMA/comments/1qb034t/github_deepseekaiengram_conditional_memory_via/" target="_blank">GitHub - deepseek-ai/Engram: Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/LocalLLaMA | Jan 12, 2026
 | By /u/TKGaming_11
            </div>
            <div class="item-summary">submitted by /u/TKGaming_11 [link] [comments].</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Transformer</span>
                <span class="tag">Neural Network</span>
                <span class="tag">Machine Learning</span>
                <span class="tag">Deep Learning</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/LocalLLaMA/comments/1qaz4je/we_finetuned_a_4b_text2sql_model_that_matches_a/" target="_blank">We fine-tuned a 4B Text2SQL model that matches a 685B teacher - query your CSV data in plain English, locally</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/LocalLLaMA | Jan 12, 2026
 | By /u/party-horse
            </div>
            <div class="item-summary">We have been exploring how far you can push small models on narrow, well-defined tasks and decided to focus on Text2SQL. We fine-tuned a small language model (4B parameters) to convert plain English questions into executable SQL queries with accuracy matching a 685B LLM (DeepSeek-V3). Because it's small, you can run it locally on your own machine, no API keys, no cloud dependencies.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Fine-tuning</span>
                <span class="tag">Model Training</span>
                <span class="tag">NLP</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/LocalLLaMA/comments/1qautxm/release_eva4b_specialized_financial_evasion/" target="_blank">[Release] Eva-4B: Specialized Financial Evasion Detection (Based on Qwen3-4B). Outperforms GPT-5.2 on domain benchmarks.</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/LocalLLaMA | Jan 12, 2026
 | By /u/Awkward_Run_9982
            </div>
            <div class="item-summary">Hi r/LocalLLaMA, I'm excited to share Eva-4B, a specialized 4B parameter model designed to detect evasive answers in corporate earnings call Q&A sessions. What it does: It classifies answers into `direct`, `intermediate`, or `fully_evasive` (using the Rasiah framework). It helps identify when executives are sidestepping analysts' questions.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Model Training</span>
                <span class="tag">Generative AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/ArtificialInteligence/comments/1qbhn7d/when_ai_takes_the_couch_psychometric_jailbreaks/" target="_blank">When AI Takes the Couch: Psychometric Jailbreaks Reveal Internal Conflict in Frontier Models</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/ArtificialInteligence | Jan 13, 2026
 | By /u/gabbygytes
            </div>
            <div class="item-summary">ABSTRACT: Frontier large language models (LLMs) such as ChatGPT, Grok and Gemini are increasingly used for mental-health support with anxiety, trauma and self-worth. Most work treats them as tools or as targets of personality tests, assuming they merely simulate inner life. We instead ask what happens when such systems are treated as psychotherapy clients.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Generative AI</span>
                <span class="tag">ChatGPT</span>
                <span class="tag">Gemini</span>
                <span class="tag">Model Training</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/LLMDevs/comments/1qaowjr/scope_raises_the_bar_by_matching_gpt4os_results/" target="_blank">SCOPE raises the bar by matching GPT-4o's results while being 160,000x smaller</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/llmdevs | Jan 12, 2026
 | By /u/MarionberrySingle538
            </div>
            <div class="item-summary">Researchers built a neural planner, SCOPE thats 160,000x smaller than frontier LLM models like GPT 40, 55x faster and produces better results compared to LLMs. SCOPE achieves this using this approach: one-shot LLM initialization + hierarchical neural planning + RL fine-tuning, allowing it to run fully independently on a single GPU with no API calls or network latency. This is really a game changer as it's faster, smarter and more sustainable for our environment. submitted by /u/MarionberrySingle538 [link] [comments].</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Neural Network</span>
                <span class="tag">Reinforcement Learning</span>
                <span class="tag">Fine-tuning</span>
                <span class="tag">GPT</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.reddit.com/r/LLMDevs/comments/1qb00ls/grad_students_phds_interested_in_coauthoring_an/" target="_blank">Grad students / PhDs interested in co-authoring an LLM benchmarking paper?</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 54</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: Reddit - r/llmdevs | Jan 12, 2026
 | By /u/turboline-ai
            </div>
            <div class="item-summary">Hi all, We‚Äôre working on a paper benchmarking LLM cost + token usage for time-series data using different formats: JSON vs CSV vs TOON vs TSLN. We already have a Python experiment setup and early results, but we‚Äôre looking for grad students, PhD candidates, or post-docs who can help with experiment design , metrics, controls, reproducibility, and multi-LLM API comparisons. This is a genuine research collaboration (not hiring, not marketing), with co-authorship for meaningful contributions.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">Model Training</span>
            </div>
        </div>

    </div>
    <div class="section">
        <h2>üì∫ Videos</h2>
        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=Nao16-6l6dQ" target="_blank">[Paper Analysis] The Free Transformer (and some Variational Autoencoder stuff)</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 48</span>
                <span class="badge badge-medium">ResearchPaper</span>
                Source: YouTube - Yannic Kilcher | Nov 01, 2025
 | By Yannic Kilcher
            </div>
            <div class="item-summary">A new transformer model, "Free Transformer," introduces latent variables to guide sequence generation, allowing for more explicit control over underlying decisions. This approach aims to improve consistency and simplify the generation process by making deliberate choices, like generating a positive or negative movie review, upfront rather than relying solely on random token sampling. The model seeks to address scenarios where data inherently depends on such latent factors.</div>
            <div class="tags">
                <span class="tag">transformer</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=EWvNQjAaOHw" target="_blank">How I use LLMs</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Feb 27, 2025
 | By Andrej Karpathy
            </div>
            <div class="item-summary">This video explores practical applications of large language models (LLMs) like ChatGPT, highlighting the growing ecosystem of similar tools from major tech companies and startups. It explains that LLMs process information as tokens and that conversations are built by sequentially adding tokens to a context window, which acts as the model's working memory. The core function of these models is to predict the next token in a sequence, a process that allows them to acquire and compress vast amounts of world knowledge.</div>
            <div class="tags">
                <span class="tag">LLM</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=7xTGNNLPyMI" target="_blank">Deep Dive into LLMs like ChatGPT</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Feb 05, 2025
 | By Andrej Karpathy
            </div>
            <div class="item-summary">Large language models like ChatGPT are built through a multi-stage process, starting with pre-training on vast amounts of filtered internet text. This data is rigorously cleaned, removing unwanted content and personally identifiable information, to create a high-quality, diverse dataset. Neural networks are then trained on this processed text to learn patterns and generate human-like responses.</div>
            <div class="tags">
                <span class="tag">GPT</span>
                <span class="tag">LLM</span>
                <span class="tag">ChatGPT</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=l8pRSuU81PU" target="_blank">Let's reproduce GPT-2 (124M)</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Jun 09, 2024
 | By Andrej Karpathy
            </div>
            <div class="item-summary">This video demonstrates how to reproduce the 124 million parameter GPT-2 model using PyTorch and Hugging Face Transformers. It details the model's architecture, including token and positional embeddings, and visualizes the learned positional embeddings to reveal their structured nature. The process highlights that reproducing this model is now more accessible and cost-effective than when it was initially released.</div>
            <div class="tags">
                <span class="tag">GPT</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=zduSFxRajkE" target="_blank">Let's build the GPT Tokenizer</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Feb 20, 2024
 | By Andrej Karpathy
            </div>
            <div class="item-summary">Tokenization is the crucial process of converting text into numerical tokens for large language models, and it significantly impacts their performance. State-of-the-art models use complex algorithms like Byte Pair Encoding to create token vocabularies, which can lead to unexpected behavior with numbers, capitalization, and non-English languages. Understanding tokenization is essential to troubleshoot many issues that appear to stem from the model architecture itself.</div>
            <div class="tags">
                <span class="tag">GPT</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=zjkBMFhNj_g" target="_blank">[1hr Talk] Intro to Large Language Models</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Andrej Karpathy | Nov 23, 2023
 | By Andrej Karpathy
            </div>
            <div class="item-summary">Large language models, like Meta's Llama 2 70b, are essentially two files: a large parameters file and a code file to run it. Training these models involves compressing vast amounts of internet text using massive GPU clusters, a process that is computationally intensive and costly. The core function of these models is to predict the next word in a sequence, a task that forces them to learn a wide range of world knowledge.</div>
            <div class="tags">
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=_uo7CXd33Uc" target="_blank">NVIDIA‚Äôs AI Finally Solved Walking In Games</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Two Minute Papers | Dec 21, 2025
 | By Two Minute Papers
            </div>
            <div class="item-summary">This research introduces a new system for physically simulated characters in computer graphics, eliminating common animation bugs like sliding feet. The system uses a "brain" (Trace) to generate paths and a "muscle" (Pacer) to control character movement through live physics simulations, allowing for more organic and realistic crowd behavior. This technology has potential applications beyond gaming, particularly in training safer self-driving cars by simulating realistic, unpredictable pedestrian behavior.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=FMMpUO1uAYk" target="_blank">What the Freakiness of 2025 in AI Tells Us About 2026</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 23, 2025
 | By AI Explained
            </div>
            <div class="item-summary">In 2025, AI models demonstrated significant advancements in reasoning and benchmark performance, with new models like Gemini 3 Pro excelling across various tasks. However, this progress also highlighted potential limitations, such as reduced output diversity when models are optimized for benchmarks. The year also saw the emergence of generative AI for dynamic world creation, the mainstreaming of AI-generated content ("AI slop") leading to trust issues, and increased government adoption of AI.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=WHqaF4jbUYU" target="_blank">Gemini Exponential, Demis Hassabis' ‚ÄòProto-AGI‚Äô coming, but ‚Ä¶</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 19, 2025
 | By AI Explained
            </div>
            <div class="item-summary">Google's Gemini 3 Flash demonstrates significant improvements over previous models, excelling in benchmarks across reasoning, knowledge, and coding. However, a key weakness is its tendency to hallucinate incorrect answers rather than admitting uncertainty, a common issue in current AI development. This highlights the ongoing challenge of balancing performance with honesty in large language models.</div>
            <div class="tags">
                <span class="tag">AGI</span>
                <span class="tag">Gemini</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=4p73Uu_jZ10" target="_blank">GPT 5.2: OpenAI Strikes Back</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 12, 2025
 | By AI Explained
            </div>
            <div class="item-summary">OpenAI's new GPT 5.2 model shows impressive benchmark results, even surpassing human experts on certain knowledge-based tasks. However, its performance is heavily influenced by the computational resources, or "thinking time," allocated, making direct comparisons with other models challenging. The effectiveness of benchmarks themselves is also questioned due to potential biases and the difficulty in preventing models from being trained on test data.</div>
            <div class="tags">
                <span class="tag">GPT</span>
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=iO844izo9kw" target="_blank">You Are Being Told Contradictory Things About AI</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Dec 05, 2025
 | By AI Explained
            </div>
            <div class="item-summary">The video explores contradictory narratives surrounding AI development. One perspective suggests AI will rapidly displace white-collar jobs, but data indicates this refers to task automation potential, not direct job losses. Another debate centers on whether scaling current AI models will lead to AGI or if new breakthroughs are needed, with experts offering opposing views on timelines and dependencies.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=9hv4nr_46Ao" target="_blank">Nano Banana Pro: But Did You Catch These 10 Details?</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - AI Explained | Nov 20, 2025
 | By AI Explained
            </div>
            <div class="item-summary">Google's Nano Banana Pro is a significant advancement in text-to-image AI, impressing with its quality and professional-level outputs. Key features include its ability to integrate live search for greater accuracy and creative double-exposure effects. However, users should still verify generated content, especially infographics, as the model can occasionally produce inaccuracies.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.youtube.com/watch?v=4yYcN_mFi18" target="_blank">PhD Bodybuilder Predicts The Future of AI (97% Certain) [Dr. Mike Israetel]</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 45</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: YouTube - Machine Learning Street Talk | Dec 24, 2025
 | By Machine Learning Street Talk
            </div>
            <div class="item-summary">The discussion explores the nature of intelligence, contrasting simulated realities with genuine experience and questioning the value of a perfect, problem-free existence. It then delves into predictions for Artificial Super Intelligence (ASI) and Artificial General Intelligence (AGI), suggesting ASI may arrive as early as 2026-2027 and AGI by 2029-2031, defined by AI systems radically exceeding human capabilities across various domains. The key takeaway is that true superintelligence will be measured not only by cognitive prowess but also by its tangible, real-world impact, such as generating novel scientific discoveries and cures.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

    </div>
    <div class="section">
        <h2>üì∞ News</h2>
        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/anthropics-new-cowork-tool-offers-claude-code-without-the-code/" target="_blank">Anthropic‚Äôs new Cowork tool offers Claude Code without the code</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">Built into the Claude Desktop app, Cowork lets users designate a specific folder where Claude can read or modify files, with further instructions given through the standard chat interface.</div>
            <div class="tags">
                <span class="tag">Claude</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/amazon-says-97-of-its-devices-can-support-alexa/" target="_blank">Amazon says 97% of its devices can support Alexa+</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">Amazon is counting on its Alexa footprint to help it gain traction in the consumer AI race.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/googles-gemini-to-power-apples-ai-features-like-siri/" target="_blank">Google‚Äôs Gemini to power Apple‚Äôs AI features like Siri</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">Apple and Google have embarked on a non-exclusive, multi-year partnership that will involve Apple using Gemini models and Google cloud technology for future foundational models.</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">Gemini</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/a-new-jersey-lawsuit-shows-how-hard-it-is-to-fight-deepfake-porn/" target="_blank">A New Jersey lawsuit shows how hard it is to fight deepfake porn</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">A number of US laws have already banned deepfake pornography ‚Äî most notably the Take It Down Act. But while specific users are clearly breaking those laws, it‚Äôs much harder to hold the entire platform accountable.</div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://techcrunch.com/2026/01/12/harmattan-ai-raises-200m-series-b-led-by-dassault-aviation-becomes-defense-unicorn/" target="_blank">Harmattan AI raises $200M Series B led by Dassault Aviation, becomes defense unicorn</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: TechCrunch AI | Jan 12, 2026
            </div>
            <div class="item-summary">French defense tech company Harmattan AI is now valued at $1.4 billion after raising a $200 million Series B round led by Dassault Aviation, which is best known for making the Rafale fighter jet.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.technologyreview.com/2026/01/12/1131193/ces-showed-me-why-chinese-tech-companies-feel-so-optimistic/" target="_blank">CES showed me why Chinese tech companies feel so optimistic</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: MIT Technology Review | Jan 12, 2026
            </div>
            <div class="item-summary">This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. I decided to go to CES kind of at the last minute.</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">AGI</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.technologyreview.com/2026/01/12/1129782/ai-large-language-models-biology-alien-autopsy/" target="_blank">Meet the new biologists treating LLMs like aliens</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: MIT Technology Review | Jan 12, 2026
            </div>
            <div class="item-summary">How large is a large language model? Think about it this way. In the center of San Francisco there‚Äôs a hill called Twin Peaks from which you can view nearly the entire city.</div>
            <div class="tags">
                <span class="tag">LLM</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.technologyreview.com/2026/01/12/1129982/hyperscale-ai-data-centers-energy-usage-2026-breakthrough-technology/" target="_blank">Hyperscale AI data centers: 10 Breakthrough Technologies 2026</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: MIT Technology Review | Jan 12, 2026
            </div>
            <div class="item-summary">In sprawling stretches of farmland and industrial parks, supersized buildings packed with racks of computers are springing up to fuel the AI race. These engineering marvels are a new species of infrastructure: supercomputers designed to train and run large language models at mind-¬≠bending scale, complete with their own specialized chips, cooling systems, and even energy‚Ä¶.</div>
            <div class="tags">
                <span class="tag">AI</span>
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.technologyreview.com/2026/01/12/1130003/mechanistic-interpretability-ai-research-models-2026-breakthrough-technologies/" target="_blank">Mechanistic interpretability: 10 Breakthrough Technologies 2026</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: MIT Technology Review | Jan 12, 2026
            </div>
            <div class="item-summary">Hundreds of millions of people now use chatbots every day. And yet the large language models that drive them are so complicated that nobody really understands what they are, how they work, or exactly what they can and can‚Äôt do‚Äînot even the people who build them. Weird, right?</div>
            <div class="tags">
                <span class="tag">model</span>
            </div>
        </div>

        <div class="item">
            <div class="item-title"><a href="https://www.technologyreview.com/2026/01/12/1130018/ai-companions-chatbots-relationships-2026-breakthrough-technology/" target="_blank">AI companions: 10 Breakthrough Technologies 2026</a></div>
            <div class="item-meta">
                <span class="badge badge-score">Score: 55</span>
                <span class="badge badge-medium">NewsArticle</span>
                Source: MIT Technology Review | Jan 12, 2026
            </div>
            <div class="item-summary">Chatbots are skilled at crafting sophisticated dialogue and mimicking empathetic behavior. They never get tired of chatting. It‚Äôs no wonder, then, that so many people now use them for companionship‚Äîforging friendships or even romantic relationships.</div>
            <div class="tags">
                <span class="tag">AI</span>
            </div>
        </div>

    </div>
</body>
</html>
